<!DOCTYPE html>
<html>
  <head>
    <title>Reconocimiento de Imágenes con python - Introducción</title>
    <link rel="stylesheet" type="text/css" href="../estilos/estilos.css">
  </head>
  <body>
    <textarea id="source">
      name: inverse
      layout: true
      class: center, middle, inverse
      ---
      template: inverse
      ![RN](../imagenes/logo_horizontal.png)
      # Introducción
      ***
      ---
      layout: false
      # Introducción
      ***
      ## Los cambios producidos por la inteligencia artificial

      - Deep Learning es el motor de la industria 4.0.

      - Cambios generados por la Inteligencia Artificial:
       - Reconocimiento de voz
       - La transcripción de voz a texto
       - Interacción con nuestros dispositivos
       - Procesamiento del lenguaje natural (Google Translate)
       - Visión por computador
       - Mejoras en robótica

      .footnote[.red["el impacto de la inteligencia artificial en la historia de la humanidad es comparable con la electricidad y el fuego" (Sundar Pichai, CEO de Google)]]

      ???
      - Se está considerando la [inteligencia artificial](https://torres.ai/que-es-la-inteligencia-artificial) como la nueva revolución industrial, corazón de lo que algunos llaman industria 4.0. Pues bien, Deep Learning es el motor de este proceso.

      - Vertiginosos avances en la calidad y prestaciones de una amplia gama de tecnologías cotidianas: en el caso del reconocimiento de voz, la transcripción de voz a texto ha experimentado avances increíbles, y ya está disponible en diferentes dispositivos.

      - Estamos interactuando cada vez más con nuestros ordenadores (y todo tipo de dispositivo) simplemente hablando con ellos.

      - También ha habido avances espectaculares en el procesamiento del lenguaje natural. Por ejemplo, simplemente haciendo clic en el símbolo de micro de Google Translate, el sistema transcribirá a otro idioma lo que está dictando. Google Translate ya permite convertir oraciones de una lengua a otra en 32 pares de idiomas, y ofrece traducción de texto para más de 100.

      - A su vez, los avances en la visión por computador también son enormes: ahora nuestros ordenadores, por ejemplo, pueden reconocer imágenes y generar descripciones textuales de su contenido en segundos.

      - Estas tres áreas son cruciales para dar rienda suelta a las mejoras en robótica, drones o automóviles sin conductor, estando la inteligencia artificial en el corazón de toda esta innovación tecnológica, que últimamente avanza tan rápidamente gracias a Deep Learning.

      - Y todo ello a pesar de que la inteligencia artificial todavía no se ha desplegado ampliamente y es difícil hacerse una idea del gran impacto que tendrá, al igual que en 1995 lo era el imaginarse el impacto futuro de internet. En aquel entonces, la mayoría de la gente no veía cómo internet era relevante para ellos y cómo iba a cambiar sus vidas.

      - Personas como Sundar Pichai, CEO de Google dicen que "el impacto de la inteligencia artificial en la historia de la humanidad es comparable con la electricidad y el fuego\[1\]". Para él, la inteligencia artificial es una de las cosas más importantes en las que la humanidad está trabajando y que al igual que la gente aprendió a utilizar el fuego para los beneficios de la humanidad, también necesitó superar sus desventajas.

      ---

      #  Inteligencia artificial, Machine Learning y Deep Learning

      Antes de continuar veamos qué entendemos por **inteligencia artificial**, **Machine Learning** y **Deep
      Learning**.

      ##  Inteligencia artificial

      ### ¿A qué nos referimos cuando hablamos de inteligencia artificial?

      - De manera simple:
       - *Inteligencia que muestran las máquinas*.

      - De manera general:
       - *El esfuerzo para automatizar tareas intelectuales normalmente realizadas por humanos*.
       - *Áreas del conocimiento relacionadas con el aprendizaje automático*.

      ???
      - Una aproximación generalista puede aceptar una definición simple en la que por inteligencia artificial nos referimos a aquella inteligencia que muestran las máquinas, en contraste con la inteligencia natural de los humanos.

      - En este sentido, una posible definición concisa y general de inteligencia artificial podría ser el esfuerzo para automatizar tareas intelectuales normalmente realizadas por humanos.

      - Como tal, el área de inteligencia artificial es un campo muy amplio que abarca muchas áreas del conocimiento relacionadas con el aprendizaje automático; incluso se incluyen muchos más enfoques no siempre catalogados como aprendizaje automático.

      - A lo largo del tiempo, a medida que los computadores han sido cada vez más capaces de "hacer cosas", se han ido cambiando las tareas o tecnologías consideradas como "inteligentes".

      - Desde los años 50, la inteligencia artificial ha experimentado varias oleadas de optimismo, seguidas por la decepción y la pérdida de financiación e interés, seguidas de nuevos enfoques, éxito y financiación.

      - Durante la mayor parte de su historia, la investigación en inteligencia artificial se ha dividido en subcampos basados en consideraciones técnicas o herramientas matemáticas concretas y con comunidades de investigación que no se comunicaban suficientemente entre sí.
      ---
      #  Inteligencia artificial, Machine Learning y Deep Learning

      ## Machine Learning

      - Soporte de los avances como el reconocimiento de voz, el procesado de lenguaje natural o la visión por computador.

      - Un gran campo de investigación y desarrollo.

      - Subcampo de la inteligencia artificial que proporciona a los ordenadores la capacidad de aprender sin ser explícitamente programados.

      - "Algoritmo" de predicción para un caso de uso particular

      - Algoritmos clasificados como: aprendizaje supervisado, aprendizaje no supervisado y Reinforcement Learning.


      ???
      - Como decíamos en el anterior apartado, avances como el reconocimiento de voz, el procesado de lenguaje natural o la visión por computador son cruciales para desencadenar mejoras en robótica, drones, coches que se conducen solos, entre muchas otras áreas que están cambiando el futuro próximo.

      - Muchos de estos avances han sido posibles gracias a una familia de técnicas conocida popularmente como Deep Learning, del que hablaremos extensamente. Pero antes creo que es interesante para hacernos una imagen global correcta especificar que Deep Learning es una subparte de una de las áreas de la inteligencia artificial conocida como Machine Learning.

      - Machine Learning, en general traducido al castellano como "aprendizaje automático", es en sí mismo un gran campo de investigación y desarrollo.

      - En concreto, Machine Learning se podría definir como el subcampo de la inteligencia artificial que proporciona a los ordenadores la capacidad de aprender sin ser explícitamente programados, es decir, sin que necesiten que el programador indique las reglas que debe seguir para lograr su tarea sino que las hace automáticamente.

      - Generalizando, podemos decir que Machine Learning consiste en desarrollar para cada problema un "algoritmo" de predicción para un caso de uso particular.

      - Estos algoritmos aprenden de los datos con el fin de encontrar patrones o tendencias para comprender qué nos dicen los datos y de esta manera construir un modelo para predecir y clasificar los elementos.

      - Dada la madurez del área de investigación en Machine Learning, existen muchos enfoques bien establecidos para el aprendizaje automático por parte de máquinas. Cada uno de ellos utiliza una estructura algorítmica diferente para optimizar las predicciones basadas en los datos recibidos.

      - Machine Learning es un amplio campo con una compleja taxonomía de algoritmos que se agrupan, en general, en tres grandes categorías: aprendizaje supervisado, aprendizaje no supervisado y Reinforcement Learning.

      ---
      #  Inteligencia artificial, Machine Learning y Deep Learning

      ## Machine Learning

      - **Aprendizaje es supervisado:** regresión lineal, la regresión logística, support vector machines, decision trees, random forest y redes neuronales.

      - **Aprendizaje no supervisado:** clustering (K-means) o principal component analysis (PCA).

      - **Reinforcement Learning:** o aprendizaje por refuerzo basado en agentes, prueba y error, recompensas y penalizaciones.

      ???
      - **Aprendizaje es supervisado:** cuando los datos que usamos para el entrenamiento incluyen la solución deseada, llamada "etiqueta" (label). Algunos de los algoritmos más populares de Machine Learning en esta categoría son la regresión lineal, la regresión logística, support vector machines, decision trees, random forest y redes neuronales.

      - **Aprendizaje no supervisado:** los datos de entrenamiento no incluyen las etiquetas, y será el algoritmo el que intentará clasificar la información por sí mismo. Algunos de los algoritmos más conocidos de esta categoría son clustering (K-means) o principal component analysis (PCA).

      - **Reinforcement Learning:** (o "aprendizaje por refuerzo", traducción de algunos autores)
       - El modelo se implementa en forma de un agente que deberá explorar un espacio desconocido y determinar las acciones a llevar a cabo mediante prueba y error: aprenderá por sí mismo gracias a las recompensas y penalizaciones que obtiene de sus acciones.
       - El agente debe crear la mejor estrategia posible (políticas) para obtener la mayor recompensa en tiempo y forma. Este aprendizaje permite ser combinado con otros tipos, y está ahora mismo muy de moda puesto que el mundo real presenta muchos de estos escenarios.
      ---
      # Inteligencia artificial, Machine Learning y Deep Learning

      ## Machine Learning

      ### Terminología básica de Machine Learning

      - Label o etiqueta.

      - Variable o feature

      - Un modelo (model en inglés)

      - Fase de training o "entrenamiento"o "aprendizaje".

      - Fase de inference o "inferencia" o "predicción".

      ???
      - En Machine Learning nos referimos a label (que también traduciremos por "etiqueta") a lo que estamos intentando predecir con un modelo.

      - En cambio, a una variable de entrada la llamaremos feature (lo traduciremos como "característica" o "variable" de un ejemplo o dato de entrada).

      - Un modelo (model en inglés) define la relación entre features y labels y tiene dos fases claramente diferenciadas para el tema que nos ocupa:
       - Fase de training (que traduciremos también por "entrenamiento"o "aprendizaje"), que es cuando se crea o se "aprende" el modelo, mostrándole los ejemplos de entrada que se tienen etiquetados; de esta manera se consigue que el modelo aprenda iterativamente las relaciones entre las features y labels de los ejemplos.
       - Fase de inference (que traduciremos por "inferencia" o "predicción"), que se refiere al proceso de hacer predicciones mediante la aplicación del modelo ya entrenado a ejemplos no etiquetados.

      ---
      # Inteligencia artificial, Machine Learning y Deep Learning

      ## Machine Learning

      ### Terminología básica de Machine Learning

      Consideremos un ejemplo simple:

      ![](../imagenes/image7.jpeg)

      ???
      Consideremos un ejemplo simple de modelo que expresa una relación lineal entre features y labels. El modelo podría expresarse de la siguiente forma:
      ![](../imagenes/image7.jpeg)

      Donde:
      - **y** es la label o etiqueta de un ejemplo de entrada. **x** la feature de ese ejemplo de entrada.
      - **w** es la pendiente de la recta y que en general le llamaremos "peso" (o weight en inglés) y es uno de los dos parámetros que se tienen que aprender el modelo durante el proceso de entrenamiento para poder usarlo luego para inferencia.
      - **b** es el punto de intersección de la recta en el eje y que llamamos "sesgo" (o bias en inglés). Este es el otro de los parámetros que deben ser aprendidos por el modelo.

      - Aunque en este modelo simple que hemos representado solo tenemos una feature de entrada, en el caso de Deep Learning veremos que tenemos muchas variables de entrada, cada una con su peso wi.

      ---
      # Inteligencia artificial, Machine Learning y Deep Learning

      ## Machine Learning

      ### Terminología básica de Machine Learning

      Un modelo basado en tres features (x1, x2, x3) puede expresarse de la siguiente manera:
      ![](../imagenes/image8.jpeg)

      De manera más general, se puede expresar como:
      ![](../imagenes/image9.jpeg)


      ???
      - Expresa el sumatorio del producto escalar entre los dos vectores (X y W) y luego suma el sesgo.
      - El parámetro sesgo b, para facilitar la formulación, a veces se expresa como el parámetro w0 (asumiendo una entrada adicional fija de x0=1).

      ---
      # Inteligencia artificial, Machine Learning y Deep Learning

      ## Machine Learning

      ### Terminología básica de Machine Learning

      - En la fase de entrenamiento de un modelo se aprenden los valores ideales para los parámetros del modelo (los pesos wi y el sesgo b).

      - En el aprendizaje supervisado, la manera de conseguirlo es aplicar un algoritmo de aprendizaje automático que obtenga el valor de estos parámetros examinando muchos ejemplos etiquetados e intentar determinar unos valores para estos parámetros del modelo que minimicen lo que llamamos **loss** ("error").

      ???
      Loss es un concepto central en Deep Learning que representa la penalización de una mala predicción. Es decir, la loss es un número que indica cuan mala ha sido una predicción en un ejemplo concreto (si la predicción del modelo es perfecta, la loss es cero).

      Para determinar este valor, como veremos más adelante, en el proceso de entrenamiento aparecerá el concepto de función de loss, y que de momento podemos ver como la función matemática que agrega las loss individuales obtenidas de los ejemplos de entrada al modelo.

      ---
      # Inteligencia artificial, Machine Learning y Deep Learning

      ## Machine Learning

      ### Terminología básica de Machine Learning

      - En este contexto, por ahora podemos considerar que la fase de entrenamiento de un modelo consiste básicamente en ajustar los parámetros (los pesos wi y el sesgo b) de tal manera que el resultado de la función de loss retorna el valor mínimo posible.

      - Finalmente, nos queda avanzar el concepto de **overfitting** ("sobreajuste") de un modelo, que se produce cuando el modelo obtenido se ajusta tanto a los ejemplos etiquetados de entrada que no puede realizar las predicciones correctas como en ejemplos de datos nuevos que nunca ha visto antes.

      ---
      # Inteligencia artificial, Machine Learning y Deep Learning

      ## Redes neuronales artificiales y Deep Learning

      - Un caso especial de algoritmos de Machine Learning son las redes neuronales artificiales. Se pueden considerar que los algoritmos son similares a las neuronas humanas y su capacidad para la obtención de resultados.

      - En Deep Learning ("aprendizaje profundo"), las estructuras algorítmicas permiten modelos que están compuestos de múltiples capas de procesamiento para aprender representaciones de datos, con múltiples niveles de abstracción que realizan una serie de transformaciones lineales y no lineales que a partir de los datos de entrada generen una salida próxima a la esperada (label).

      - El aprendizaje supervisado, en este caso, consiste en obtener los parámetros de esas transformaciones (los pesos wi y el sesgo b), y consigue que esas transformaciones sean óptimas, es decir, que la salida producida y la esperada difieran muy poco.

      ---
      # Inteligencia artificial, Machine Learning y Deep Learning

      ## Redes neuronales artificiales y Deep Learning

      Una aproximación gráfica simple a una red neuronal Deep Learning es

      ![](../imagenes/image10.jpeg)

      ???
      - Aquí representamos una red neuronal artificial con 3 capas:
       - Una de entrada (input layer) que recibe los datos de entrada
       - Una de salida (output layer) que devuelve la predicción realizada.
       - Las capas que tenemos en medio se llaman capas ocultas (hidden layers) y podemos tener muchas, cada una con distinta cantidad de neuronas.

      - Las neuronas, representadas por los círculos, estarán interconectadas unas con otras de diferente manera entre las neuronas de las distintas capas.

      ---
      # Inteligencia artificial, Machine Learning y Deep Learning

      ## Redes neuronales artificiales y Deep Learning

      - En general, hoy en día estamos manejando redes neuronales artificiales con muchísimas capas, que literalmente están apiladas una encima de la otra; *de aquí el concepto de deep*.

      - Cada una de ellas está a su vez compuesta por muchísimas neuronas, cada una con sus parámetros (los pesos wi y el sesgo b) que, a su vez, realizan una transformación simple de los datos que reciben de neuronas de la capa anterior para pasarlos a las de la capa posterior.

      - La unión de todas permite descubrir patrones complejos.

      - Los avances en Deep Learning han mejorado drásticamente el estado de la técnica en reconocimiento de voz, reconocimiento de objetos visuales, detección de objetos y muchos otros dominios, siendo una de las técnicas que han puesto la inteligencia artificial en el foco de interés de las empresas y de aquí el gran interés que ahora mismo suscitan.
      ???
      - Aunque Deep Learning a menudo se presenta envuelto de una cierta mística, con referencias a algoritmos que "funcionan como el cerebro", que "piensan" o "entienden", sus conceptos básicos pueden ser explicados de manera relativamente fácil.

      - Antes de acabar, me gustaría dar una magnitud del problema que conlleva programar en estos momentos los algoritmos de Deep Learning:

       - Diferentes capas sirven para diferentes propósitos, y cada parámetro e hiperparámetro importa mucho en el resultado final; esto lo hace extremadamente complicado a la hora de intentar afinar la programación de un modelo de red neuronal.
       - Esto no implica que sea algo misterioso, si bien es cierto que queda mucho por investigar, sino que simplemente hace falta muchas horas de aprendizaje y práctica.
      ---
      # Inteligencia artificial, Machine Learning y Deep Learning

      ## Redes neuronales artificiales y Deep Learning

      La siguiente figura resume visualmente la idea intuitiva de que Deep Learning es solo una parte de la inteligencia artificial, aunque en estos momentos quizás es la más dinámica y la que está haciendo realmente vibrar a la comunidad científica.

      ![](../imagenes/image11.jpeg)

      ---
      # Inteligencia artificial, Machine Learning y Deep Learning

      ## ¿Por qué ahora?

      - Apple, Alphabet (la compañía matriz de Google), Amazon, Facebook y Microsoft son las empresas dominantes en la economía actual. Todas ellas dominan la nueva era digital en que nos encontramos inmersos.

      - Estamos hablando de empresas que basan su poderío en inteligencia artificial en general, y en particular Deep Learning.

      - John McCarthy acuñó el término **inteligencia artificial** en la década de los 50 y fue uno de los padres fundadores de la inteligencia artificial junto con Marvin Minsky.

      - También en 1958 Frank Rosenblatt construyó un prototipo de red neuronal, que llamó el Perceptron.

      ---
      # Inteligencia artificial, Machine Learning y Deep Learning

      ## ¿Por qué ahora?

      - Las ideas clave de las redes neuronales Deep Learning para la visión por computador ya se conocían en 1989.

      - Los algoritmos fundamentales de Deep Learning para series temporales como LSTM ya fueron desarrollados en 1997, por poner algunos ejemplos.

      ### ¿por qué el boom actual de la inteligencia artificial?

      - La disponibilidad de los datos

      - La capacidad de computo disponible y la democratización de la computación

      ---
      # Inteligencia artificial, Machine Learning y Deep Learning

      ## ¿Por qué ahora?

      ### La disponibilidad de los datos:
      - La inteligencia artificial requiere grandes conjuntos de datos para el entrenamiento de sus modelos.

      - Los recursos de datos especializados en bases de datos abiertas como ImageNet, MNIST, CIFAR, SVHN, STL o IMDB.

      - Plataformas de competencias que motivan a investigadores e ingenieros como ImageNet y Kaggle.

      ???
      - La inteligencia artificial requiere grandes conjuntos de datos para el entrenamiento de sus modelos aunque, afortunadamente, la creación y disponibilidad de datos ha crecido exponencialmente gracias el enorme decrecimiento de coste e incremento de fiabilidad de la generación de datos: fotos digitales, sensores más baratos y precisos, etc.

      - Además, las mejoras en el hardware de almacenamiento de los últimos años, asociado a los espectaculares avances en técnica para su gestión con bases de datos NoSQL, han permitido disponer de enormes conjuntos de datos para entrenar a los modelos de inteligencia artificial.

      - Más allá de los aumentos en la disponibilidad de datos que ha propiciado internet y sus múltiples aplicaciones, los recursos de datos especializados han catalizado el progreso del área.

      - Muchas bases de datos abiertas han apoyado el rápido desarrollo de algoritmos de inteligencia artificial. Un ejemplo ImageNet, la base de datos, disponible libremente con más de 10 millones de imágenes etiquetadas a mano.

      - Pero lo que hace ImageNet especial no es precisamente su tamaño, sino la competición que anualmente realiza, siendo una excelente manera de motivar a investigadores e ingenieros.

      - Pero ImageNet solo es una de las bases de datos disponibles que se han usado para entrenar redes Deep Learning durante estos últimos años; muchas otras han sido populares, como MNIST, CIFAR, SVHN, STL o IMDB.

      - También es importante mencionar aquí Kaggle, una plataforma que aloja competiciones de análisis de datos donde compañías e investigadores aportan sus datos mientras ingenieros de datos de todo el mundo compiten por crear los mejores modelos de predicción o clasificación.

      ---
      # Inteligencia artificial, Machine Learning y Deep Learning

      ## ¿Por qué ahora?

      ### Disponibilidad y capacidad de computo

      - Cloud Computing

      - Artificial Intelligence algorithms as a Service (AI-as-a-Service)

      - **AIaaS** ofrecido por Amazon, Microsoft, Google e IBM
      ???
      - La inteligencia artificial hasta ahora ha sido principalmente el juguete de las grandes compañías de tecnología como Amazon, Baidu, Google o Microsoft

      - Para muchos otros los sistemas de inteligencia artificial hasta ahora han sido demasiado costosos y demasiado difíciles de implementar por completo.

      - Pero ahora gracias a **Cloud Computing** las empresas pueden disponer de acceso a grandes centros de procesado de datos con cientos de miles de servidores dentro.

      - Mediante Cloud Computing se ofrece acceso a una capacidad de computación que antes solo estaba disponible para grandes organizaciones o gobiernos.

      - Los proveedores de Cloud están ahora ofreciendo lo que se conoce como **Artificial Intelligence algorithms as a Service (AI-as-a-Service)**, servicios de inteligencia artificial a través de Cloud que pueden entrelazarse y trabajar conjuntamente con aplicaciones internas de las empresas a través de simples API REST.

      - Esto implica que está al alcance de casi todos, ya que se trata de un servicio que solo se paga por el tiempo utilizado. Esto es disruptivo, porque ahora mismo permite a los desarrolladores de software usar y poner prácticamente cualquier algoritmo de inteligencia artificial en producción en un santiamén.

      - Amazon, Microsoft, Google e IBM están liderando esta oleada de servicios **AIaaS** que permiten desde entrenamientos a puestas en producción de manera rápida.

      - Sin duda, la inteligencia artificial liderará la próxima revolución. Su éxito dependerá en gran medida de la creatividad de las empresas y no tanto de la tecnología hardware en parte gracias a Cloud Computing.
      ---
      ---
      template: inverse
      ![RN](../imagenes/logo_horizontal.png)
      # El entorno de trabajo
      ***
      ---
      # El entorno de trabajo

      ## Un mundo open-source para la comunidad Deep Learning

      - Hace algunos años, Deep Learning requería experiencia en lenguajes como C++ y CUDA; hoy en día, con habilidades básicas de Python es suficiente.

      - Frameworks como Keras facilitan enormemente la creación y entrenamiento de los modelos y permiten abstraer las peculiaridades del hardware al diseñador del algoritmo para acelerar los procesos de entrenamiento.

      - Los frameworks como TensorFlow, Keras y PyTorch son los más dinámicos en estos momentos si nos basamos en los contributors y commits o starts de estos proyectos en GitHub.

      ---
      # El entorno de trabajo

      ## Un mundo open-source para la comunidad Deep Learning

      **TensorFlow:**
      - En concreto, recientemente ha tomado mucho impulso TensorFlow y sin duda es el dominante. Fue originalmente desarrollado por investigadores e ingenieros del grupo de Google Brain en Google.

      - El sistema fue diseñado para facilitar la investigación en Machine Learning y hacer más rápido la transición de un prototipo de investigación a un sistema de producción.

      **Keras:**
      - Le sigue Keras con una API de alto nivel para redes neuronales, que lo convierte en el entorno perfecto para iniciarse en el tema. El código se especifica en Python, y en estos momentos es capaz de ejecutarse encima de tres entornos destacados: TensorFlow, CNTK o Theano.

      ---
      # El entorno de trabajo

      ## Un mundo open-source para la comunidad Deep Learning

      **PyTorch:**
      - PyTorch y Torch son dos entornos de Machine Learning implementados en C, usando OpenMP y CUDA para sacar provecho de infraestructuras altamente paralelas.

      - PyTorch es la versión más focalizada para Deep Learning y basada en Python, desarrollado por Facebook. Permite mucha flexibilidad en la construcción de las redes neuronales y tiene tensores dinámicos, entre otras cosas.

      **Otras opciones:**
      - Scikit-learn que se usa muy a menudo en la comunidad de Deep Learning para el preprocesado de los datos.
      - Theano (Montreal Institute of Learning Algortithms).
      -  Caffe (Universidad de Berkeley).
      - Caffe2 (Facebook Research)
      - CNTK\[38\] (Microsoft).
      - y muchos otros.

      ---
      # El entorno de trabajo

      ## Jupyter notebook

      - Debido a que Keras es básicamente una librería de Python, requerimos hacer un uso completo del intérprete de Python.

      - Jupyter, es un entorno de desarrollo muy extendido que permite sacar partido a la interactividad de Python y, a la vez, proporciona una gran versatilidad para compartir parte de códigos con anotaciones a través de la comodidad e independencia de plataforma que ofrece un navegador web.

      - Los notebook son usados a menudo para desarrollar redes neuronales en la comunidad de científicos e ingenieros de datos.

      - Un notebook es un fichero generado por Jupyter Notebook o Jupyter Lab que se puede editar desde un navegador web, permitiendo mezclar la ejecución de código Python con anotaciones.

      ---
      # El entorno de trabajo

      ## Keras

      - Para la instalación de la librería de Keras en la página oficial, encontrará una versión actualizada de los pasos a seguir para la instalación de la última versión de la librería.

      - En esta página podemos ver la indicación de tener previamente instalado uno de los backend que necesita, y nos recomienda usar TensorFlow.

      - Para ello pueden visitar la página de instalación de Tensorflow y seleccionar la versión de acuerdo a su sistema operativo.

      - Para instalar Keras solo les queda seguir las instrucciones de su página de instalación.

      https://keras.io/getting_started/

      https://www.tensorflow.org/overview/

      ---
      # El entorno de trabajo

      ## Ambiente de Desarrollo python anaconda:

      - La Suite de trabajo es la suite Anaconda la cual:
       - Facilita la tarea de instalar el ambiente e incluye Jupyter Notebooks
       - Hacer ejercicios paso a paso en Machine Learning mediante Jupyter Notebooks.
       - Crear visualizaciones de datos y escribir comentarios.
       - Es multiplataforma y se puede utilizar para Windows, Linux y Macintosh.

       https://www.anaconda.com/products/individual

    </textarea>
    <script src="../scripts/remark.js"></script>
    <script>
       var slideshow = remark.create();
    </script>
  </body>
</html>
